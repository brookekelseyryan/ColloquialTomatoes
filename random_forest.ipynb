{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unexpected-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "declared-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As a popular sport, surfing was liked by many ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'The Rookie' was a wonderful movie about the s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I just came back from a pre-release viewing of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had a personal interest in this movie. When ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie has so many wonderful elements to i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  As a popular sport, surfing was liked by many ...      1\n",
       "1  'The Rookie' was a wonderful movie about the s...      1\n",
       "2  I just came back from a pre-release viewing of...      1\n",
       "3  I had a personal interest in this movie. When ...      1\n",
       "4  This movie has so many wonderful elements to i...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('training_reviews.csv', names = ['Text', 'Label'], header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "arranged-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "\n",
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_up_text(text, flag = 0):\n",
    "    text_1 = preprocessor(text)\n",
    "    text_2 = remove_special_characters(text_1)\n",
    "    \n",
    "    if flag == 1:\n",
    "        text_2 = simple_stemmer(text_2)\n",
    "        \n",
    "    return text_2\n",
    "\n",
    "\n",
    "# rev = df1.iloc[0]['Text']\n",
    "# print(clean_up_text(rev)) ## call with no stemming\n",
    "# print()\n",
    "# print(clean_up_text(rev, 1)) ## call like this when stemming\n",
    "\n",
    "\n",
    "#set flag = 1, if you want to stem\n",
    "def process_data(data):\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        #print(data[i])\n",
    "        #print(data['Text'][i])\n",
    "        data['Text'][i] = clean_up_text(data['Text'][i])\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "df = process_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assured-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, 0].values\n",
    "Y = df.iloc[:, 1].values\n",
    "# df1 = df[df.Label == 2]\n",
    "# df2 = df[df.Label == 1]\n",
    "\n",
    "#### DO Nueral_NEt stuff here\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "intended-physiology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('anger', 1), ('anticipation', 0), ('disgust', 0), ('fear', 2), ('joy', 1), ('negative', 3), ('positive', 1), ('sadness', 0), ('surprise', 0), ('trust', 2)]\n",
      "1\n",
      "[('anger', 0), ('anticipation', 4), ('disgust', 0), ('fear', 0), ('joy', 4), ('negative', 0), ('positive', 5), ('sadness', 0), ('surprise', 2), ('trust', 4)]\n",
      "[('anger', 1), ('anticipation', 2), ('disgust', 1), ('fear', 1), ('joy', 3), ('negative', 4), ('positive', 7), ('sadness', 3), ('surprise', 1), ('trust', 5)]\n",
      "[('anger', 2), ('anticipation', 6), ('disgust', 2), ('fear', 2), ('joy', 7), ('negative', 5), ('positive', 13), ('sadness', 2), ('surprise', 2), ('trust', 13)]\n",
      "[('anger', 1), ('anticipation', 4), ('disgust', 0), ('fear', 1), ('joy', 8), ('negative', 3), ('positive', 10), ('sadness', 3), ('surprise', 6), ('trust', 5)]\n",
      "[('anger', 21), ('anticipation', 26), ('disgust', 18), ('fear', 30), ('joy', 22), ('negative', 44), ('positive', 60), ('sadness', 20), ('surprise', 19), ('trust', 33)]\n",
      "[('anger', 2), ('anticipation', 5), ('disgust', 2), ('fear', 5), ('joy', 0), ('negative', 5), ('positive', 6), ('sadness', 2), ('surprise', 2), ('trust', 6)]\n",
      "[('anger', 4), ('anticipation', 5), ('disgust', 4), ('fear', 9), ('joy', 0), ('negative', 11), ('positive', 9), ('sadness', 9), ('surprise', 3), ('trust', 6)]\n",
      "[('anger', 0), ('anticipation', 6), ('disgust', 2), ('fear', 0), ('joy', 4), ('negative', 1), ('positive', 7), ('sadness', 0), ('surprise', 3), ('trust', 5)]\n",
      "[('anger', 0), ('anticipation', 1), ('disgust', 0), ('fear', 0), ('joy', 2), ('negative', 1), ('positive', 5), ('sadness', 0), ('surprise', 1), ('trust', 2)]\n",
      "1001\n",
      "2001\n",
      "3001\n",
      "4001\n",
      "5001\n",
      "6001\n",
      "7001\n",
      "8001\n",
      "9001\n",
      "10001\n",
      "11001\n",
      "12001\n",
      "13001\n",
      "14001\n",
      "15001\n",
      "16001\n",
      "17001\n",
      "18001\n",
      "19001\n",
      "20001\n",
      "21001\n",
      "22001\n",
      "23001\n",
      "24001\n",
      "[[115, 1, 0, 0, 2, 1, 3, 1, 0, 0, 2], [72, 0, 4, 0, 0, 4, 0, 5, 0, 2, 4], [127, 1, 2, 1, 1, 3, 4, 7, 3, 1, 5], [330, 2, 6, 2, 2, 7, 5, 13, 2, 2, 13], [125, 1, 4, 0, 1, 8, 3, 10, 3, 6, 5]] [1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "######### Getting Feature Sets from Lexicon\n",
    "\n",
    "from nrclex import NRCLex\n",
    "\n",
    "#Feature Set, is ordered by Length of review, followed by raw_emotio\n",
    "#Foallaowed by affect_frequencies\n",
    "\n",
    "X_2 = []\n",
    "Y_2 = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if i% 1000 == 1:\n",
    "        print(i)\n",
    "        \n",
    "    review = df['Text'][i]\n",
    "    \n",
    "    text_object = NRCLex(review)\n",
    "    review = review.split(\" \")\n",
    "    \n",
    "    feature_list = []\n",
    "    feature_list.append(len(review))\n",
    "    \n",
    "    raw_emotions = [\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"negative\", \"positive\", \"sadness\", \"surprise\", \"trust\"]\n",
    "    \n",
    "    raw_emotion = text_object.raw_emotion_scores\n",
    "    for raw_em in raw_emotions:\n",
    "        if raw_em not in raw_emotion:\n",
    "            raw_emotion[raw_em] = 0\n",
    "    raw_emotion = [(k,v) for k,v in raw_emotion.items()]\n",
    "    raw_emotion.sort()\n",
    "    if(i < 10):\n",
    "        print(raw_emotion)\n",
    "    raw_emotion = [v for (k,v) in raw_emotion]\n",
    "    feature_list.extend(raw_emotion)\n",
    "    \n",
    "#     affect_frequencies = text_object.affect_frequencies\n",
    "#     affect_frequencies = [(k,v) for k,v in affect_frequencies.items()]\n",
    "#     affect_frequencies.sort()\n",
    "#     affect_frequencies = [v for (k,v) in affect_frequencies]\n",
    "#     feature_list.extend(affect_frequencies)\n",
    "    \n",
    "    X_2.append(feature_list)\n",
    "    Y_2.append(df['Label'][i])\n",
    "    \n",
    "    \n",
    "print(X_2[0:5], Y_2[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aggressive-capacity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6', 'Feature_7', 'Feature_8', 'Feature_9', 'Feature_10', 'Feature_11']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/ipykernel_launcher.py:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import DataFrame\n",
    "\n",
    "### number of features\n",
    "feature_len = len(X_2[0])\n",
    "label_list = [\"Feature_\" + str(i) for i in range(1, feature_len + 1)]\n",
    "\n",
    "print(label_list)\n",
    "X_2 = DataFrame(X_2, columns = label_list)\n",
    "Y_2 = DataFrame(Y_2, columns = [\"Label\"])\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_2,Y_2, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train, Y_train)\n",
    "Y_pred = regressor.predict(X_test)\n",
    "\n",
    "#print(Y_pred)\n",
    "\n",
    "\n",
    "# print(confusion_matrix(Y_test,Y_pred))\n",
    "# print(classification_report(Y_test,Y_pred))\n",
    "#print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "humanitarian-retrieval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0]\n",
      "[2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0]\n",
      "[[1558  938]\n",
      " [ 716 1788]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.62      0.65      2496\n",
      "           2       0.66      0.71      0.68      2504\n",
      "\n",
      "    accuracy                           0.67      5000\n",
      "   macro avg       0.67      0.67      0.67      5000\n",
      "weighted avg       0.67      0.67      0.67      5000\n",
      "\n",
      "0.6692\n"
     ]
    }
   ],
   "source": [
    "# print(max(Y_pred))\n",
    "# print(min(Y_pred))\n",
    "# print(Y_pred[0:100])\n",
    "# print(Y_train[0:100])\n",
    "print(Y_pred[0:100])\n",
    "Y_pred = [y.round() for y in Y_pred]\n",
    "# print(Y_pred[0:100])\n",
    "print(Y_pred[0:100])\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "alike-collar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt', n_jobs=-1, random_state=50,\n",
       "                       verbose=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RSEED = 50\n",
    "\n",
    "train, test, train_labels, test_labels = train_test_split(X_2, Y_2, \n",
    "                                                          stratify = Y_2,\n",
    "                                                          test_size = 0.2, \n",
    "                                                          random_state = RSEED)\n",
    "# X_2 = DataFrame(X_2, columns = label_list)\n",
    "# Y_2 = DataFrame(Y_2, columns = [\"Label\"])\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X_2,Y_2, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               random_state=RSEED, \n",
    "                               max_features = 'sqrt',\n",
    "                               n_jobs=-1, verbose = 1)\n",
    "\n",
    "model.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "broke-beijing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of nodes 8893\n",
      "Average maximum depth 29\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "\n",
    "for ind_tree in model.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "entire-laugh",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "train_rf_predictions = model.predict(train)\n",
    "train_rf_probs = model.predict_proba(train)[:, 1]\n",
    "\n",
    "rf_predictions = model.predict(test)\n",
    "rf_probs = model.predict_proba(test)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "composed-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.694\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels, rf_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
