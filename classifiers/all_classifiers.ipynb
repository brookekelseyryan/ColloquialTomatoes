{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "toxic-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liberal-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv('training_reviews.csv', names = ['Text', 'Label'], header = None)\n",
    "df_testing = pd.read_csv('testing_set.csv', names = ['Text', 'Label'], header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "played-royal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "\n",
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_up_text(text, flag = 0):\n",
    "    text_1 = preprocessor(text)\n",
    "    text_2 = remove_special_characters(text_1)\n",
    "    \n",
    "    if flag == 1:\n",
    "        text_2 = simple_stemmer(text_2)\n",
    "        \n",
    "    return text_2\n",
    "\n",
    "# rev = df1.iloc[0]['Text']\n",
    "# print(clean_up_text(rev)) ## call with no stemming\n",
    "# print()\n",
    "# print(clean_up_text(rev, 1)) ## call like this when stemming\n",
    "\n",
    "\n",
    "#set flag = 1, if you want to stem\n",
    "def process_data(data, flag = 0):\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if i%1000 == 0:\n",
    "            print(i)\n",
    "        data['Text'][i] = clean_up_text(data['Text'][i], flag)\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "df_training = process_data(df_training)\n",
    "df_testing = process_data(df_testing)\n",
    "df_training_stemmed = process_data(df_training, flag = 1)\n",
    "df_testing_stemmed = process_data(df_testing, flag = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "personalized-aquarium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1001\n",
      "2001\n",
      "3001\n",
      "4001\n",
      "5001\n",
      "6001\n",
      "7001\n",
      "8001\n",
      "9001\n",
      "10001\n",
      "11001\n",
      "12001\n",
      "13001\n",
      "14001\n",
      "15001\n",
      "16001\n",
      "17001\n",
      "18001\n",
      "19001\n",
      "20001\n",
      "21001\n",
      "22001\n",
      "23001\n",
      "24001\n",
      "1\n",
      "1001\n",
      "2001\n",
      "3001\n",
      "4001\n",
      "5001\n",
      "6001\n",
      "7001\n",
      "8001\n",
      "9001\n",
      "10001\n",
      "11001\n",
      "12001\n",
      "13001\n",
      "14001\n",
      "15001\n",
      "16001\n",
      "17001\n",
      "18001\n",
      "19001\n",
      "20001\n",
      "21001\n",
      "22001\n",
      "23001\n",
      "24001\n"
     ]
    }
   ],
   "source": [
    "from nrclex import NRCLex\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Feature Set, is ordered by Length of review, followed by raw_emotio\n",
    "#Foallaowed by affect_frequencies\n",
    "\n",
    "\n",
    "def generate_features_via_lexicon(df):\n",
    "    \n",
    "    X_2 = []\n",
    "    Y_2 = []\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if i% 1000 == 1:\n",
    "            print(i)\n",
    "\n",
    "        review = df['Text'][i]\n",
    "\n",
    "        text_object = NRCLex(review)\n",
    "        review = review.split(\" \")\n",
    "\n",
    "        feature_list = []\n",
    "        feature_list.append(len(review))\n",
    "\n",
    "        raw_emotions = [\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"negative\", \"positive\", \"sadness\", \"surprise\", \"trust\"]\n",
    "        affect_freq = raw_emotions = [\"anger\", \"anticip\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"negative\", \"positive\", \"sadness\", \"surprise\", \"trust\"]\n",
    "\n",
    "\n",
    "        raw_emotion = text_object.raw_emotion_scores\n",
    "        for raw_em in raw_emotions:\n",
    "            if raw_em not in raw_emotion:\n",
    "                raw_emotion[raw_em] = 0\n",
    "        raw_emotion = [(k,v) for k,v in raw_emotion.items()]\n",
    "        raw_emotion.sort()\n",
    "        #if(i < 10):\n",
    "            #print(raw_emotion)\n",
    "        raw_emotion = [v for (k,v) in raw_emotion]\n",
    "        feature_list.extend(raw_emotion)\n",
    "\n",
    "        affect_frequencies = text_object.affect_frequencies\n",
    "        for af in affect_freq:\n",
    "            if af not in affect_frequencies:\n",
    "                affect_frequencies[af] = 0\n",
    "        affect_frequencies = [(k,v) for k,v in affect_frequencies.items()]\n",
    "        affect_frequencies.sort()\n",
    "        affect_frequencies = [v for (k,v) in affect_frequencies]\n",
    "        feature_list.extend(affect_frequencies)\n",
    "\n",
    "        X_2.append(feature_list)\n",
    "        Y_2.append(df['Label'][i])\n",
    "        \n",
    "    feature_len = len(X_2[0])\n",
    "    label_list = [\"Feature_\" + str(i) for i in range(1, feature_len + 1)]\n",
    "\n",
    "    X_2 = DataFrame(X_2, columns = label_list)\n",
    "    Y_2 = DataFrame(Y_2, columns = [\"Label\"])\n",
    "\n",
    "    return X_2, Y_2\n",
    "\n",
    "\n",
    "X1, Y1 = generate_features_via_lexicon(df_training)\n",
    "X2, Y2 = generate_features_via_lexicon(df_training_stemmed)\n",
    "\n",
    "\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1,Y1, test_size = 0.2, random_state = 0)\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X2,Y2, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "guided-logan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1001\n",
      "2001\n",
      "3001\n",
      "4001\n",
      "5001\n",
      "6001\n",
      "7001\n",
      "8001\n",
      "9001\n",
      "10001\n",
      "11001\n",
      "12001\n",
      "13001\n",
      "14001\n",
      "15001\n",
      "16001\n",
      "17001\n",
      "18001\n",
      "19001\n",
      "20001\n",
      "21001\n",
      "22001\n",
      "23001\n",
      "24001\n",
      "1\n",
      "1001\n",
      "2001\n",
      "3001\n",
      "4001\n",
      "5001\n",
      "6001\n",
      "7001\n",
      "8001\n",
      "9001\n",
      "10001\n",
      "11001\n",
      "12001\n",
      "13001\n",
      "14001\n",
      "15001\n",
      "16001\n",
      "17001\n",
      "18001\n",
      "19001\n",
      "20001\n",
      "21001\n",
      "22001\n",
      "23001\n",
      "24001\n"
     ]
    }
   ],
   "source": [
    "X1_Test, Y1_Test = generate_features_via_lexicon(df_testing)\n",
    "X2_Test, Y2_Test = generate_features_via_lexicon(df_testing_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "modern-remedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on validation: 0.659\n",
      "score on test: 0.6546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on validation: 0.659\n",
      "score on test: 0.6546\n"
     ]
    }
   ],
   "source": [
    "##Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X1_train, Y1_train)\n",
    "print(\"score on validation: \" + str(lr.score(X1_test, Y1_test)))\n",
    "print(\"score on test: \"+ str(lr.score(X1_Test, Y1_Test)))\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X2_train, Y2_train)\n",
    "print(\"score on validation: \" + str(lr.score(X2_test, Y2_test)))\n",
    "print(\"score on test: \"+ str(lr.score(X2_Test, Y2_Test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "present-dutch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on validation: 0.5564\n",
      "score on Test: 0.57404\n",
      "score on validation: 0.562\n",
      "score on Test: 0.57356\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X1_train, Y1_train)\n",
    "print(\"score on validation: \"  + str(clf.score(X1_test, Y1_test)))\n",
    "print(\"score on Test: \" + str(clf.score(X1_Test, Y1_Test)))\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X2_train, Y2_train)\n",
    "print(\"score on validation: \"  + str(clf.score(X2_test, Y2_test)))\n",
    "print(\"score on Test: \" + str(clf.score(X2_Test, Y2_Test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hearing-piano",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on validation: 0.6122\n",
      "score on Test: 0.6142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on validation: 0.6126\n",
      "score on Test: 0.61452\n"
     ]
    }
   ],
   "source": [
    "#Bagging Decision Tree\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# max_samples: maximum size 0.5=50% of each sample taken from the full dataset\n",
    "# max_features: maximum of features 1=100% taken here all 10K \n",
    "# n_estimators: number of decision trees \n",
    "bg=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "bg.fit(X1_train, Y1_train)\n",
    "print(\"score on validation: \" + str(bg.score(X1_test, Y1_test)))\n",
    "print(\"score on Test: \"+ str(bg.score(X1_Test, Y1_Test)))\n",
    "\n",
    "bg=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "bg.fit(X2_train, Y2_train)\n",
    "print(\"score on validation: \" + str(bg.score(X2_test, Y2_test)))\n",
    "print(\"score on Test: \"+ str(bg.score(X2_Test, Y2_Test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "western-present",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on validation: 0.654\n",
      "score on Test: 0.65172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on validation: 0.654\n",
      "score on Test: 0.65172\n"
     ]
    }
   ],
   "source": [
    "#Boosting Decision Tree\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=4),n_estimators=10,learning_rate=0.6)\n",
    "adb.fit(X1_train, Y1_train)\n",
    "print(\"score on validation: \" + str(adb.score(X1_test, Y1_test)))\n",
    "print(\"score on Test: \"+ str(adb.score(X1_Test, Y1_Test)))\n",
    "\n",
    "adb.fit(X2_train, Y2_train)\n",
    "print(\"score on validation: \" + str(adb.score(X2_test, Y2_test)))\n",
    "print(\"score on Test: \"+ str(adb.score(X2_Test, Y2_Test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "turned-andorra",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on Validation: 0.6644\n",
      "score on Test: 0.65384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on Validation: 0.665\n",
      "score on Test: 0.6526\n"
     ]
    }
   ],
   "source": [
    "## Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# n_estimators = number of decision trees\n",
    "rf = RandomForestClassifier(n_estimators=30, max_depth=9)\n",
    "rf.fit(X1_train, Y1_train)\n",
    "print(\"score on Validation: \" + str(rf.score(X1_test, Y1_test)))\n",
    "print(\"score on Test: \"+ str(rf.score(X1_Test, Y1_Test)))\n",
    "\n",
    "rf.fit(X2_train, Y2_train)\n",
    "print(\"score on Validation: \" + str(rf.score(X2_test, Y2_test)))\n",
    "print(\"score on Test: \"+ str(rf.score(X2_Test, Y2_Test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "charged-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on validation (sampling): 0.5748\n",
      "score on Test (sampling): 0.57324\n",
      "score on validation (rounding): 0.626\n",
      "score on Test (rounding): 0.62668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagheera/.local/lib/python3.6/site-packages/ipykernel_launcher.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on validation (sampling): 0.569\n",
      "score on Test (sampling): 0.56672\n",
      "score on validation (rounding): 0.626\n",
      "score on Test (rounding): 0.62668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def sampling(Y):\n",
    "    ret_Y = []\n",
    "    for y in Y:\n",
    "        e = np.random.binomial(size =1, n=1, p = y-1)\n",
    "        ret_Y.append(1 + e)\n",
    "    return ret_Y\n",
    "\n",
    "def rounding(Y):\n",
    "    ret_Y = []\n",
    "    for y in Y:\n",
    "        ret_Y.append(y.round())\n",
    "    return ret_Y\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X1_train, Y1_train)\n",
    "Y_pred = regressor.predict(X1_test)\n",
    "Y1_pred = regressor.predict(X1_Test)\n",
    "\n",
    "print(\"score on validation (sampling):\", accuracy_score(Y1_test, sampling(Y_pred)))\n",
    "print(\"score on Test (sampling):\", accuracy_score(Y1_Test, sampling(Y1_pred)))\n",
    "print(\"score on validation (rounding):\", accuracy_score(Y1_test, rounding(Y_pred)))\n",
    "print(\"score on Test (rounding):\", accuracy_score(Y1_Test, rounding(Y1_pred)))\n",
    "\n",
    "regressor.fit(X2_train, Y2_train)\n",
    "Y_pred_2 = regressor.predict(X2_test)\n",
    "Y2_pred_2 = regressor.predict(X2_Test)\n",
    "\n",
    "print(\"score on validation (sampling):\", accuracy_score(Y2_test, sampling(Y_pred_2)))\n",
    "print(\"score on Test (sampling):\", accuracy_score(Y2_Test, sampling(Y2_pred_2)))\n",
    "print(\"score on validation (rounding):\", accuracy_score(Y2_test, rounding(Y_pred_2)))\n",
    "print(\"score on Test (rounding):\", accuracy_score(Y2_Test, rounding(Y2_pred_2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
